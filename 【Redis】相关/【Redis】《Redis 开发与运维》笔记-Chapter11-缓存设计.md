###### 十一、缓存设计

1、缓存的收益和成本

- 缓存加入后带来的收益：
    1. 加速读写：因为缓存通常都是全内存的（例如Redis、Memcache），而存储层通常读写性能不够强悍（例如MySQL），通过缓存的使用可以有效地加速读写，优化用户体验。
    2. 降低后端负载：帮助后端减少访问量和复杂计算（例如很复杂的SQL语句），在很大程度降低了后端的负载。
- 缓存加入后带来的成本：
    1. 数据不一致性：缓存层和存储层的数据存在着一定时间窗口的不一致性，时间窗口跟更新策略有关。
    2. 代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑，增大了开发者维护代码的成本。
    3. 运维成本：以Redis Cluster为例，加入后无形中增加了运维成本。
- 缓存的使用场景基本包含如下两种：
    1. 开销大的复杂计算：以MySQL为例子，一些复杂的操作或者计算（例如大量联表操作、一些分组计算），如果不加缓存，不但无法满足高并发量，同时也会给MySQL带来巨大的负担。
    2. 加速请求响应：即使查询单条后端数据足够快（例如select*from table where id=），那么依然可以使用缓存，以Redis为例子，每秒可以完成数万次读写，并且提供的批量操作可以优化整个IO链的响应时间。

2、缓存更新策略

1）LRU/LFU/FIFO算法剔除
- 使用场景：剔除算法通常用于缓存使用量超过了预设的最大值时候，如何对现有的数据进行剔除。例如Redis使用maxmemory-policy这个配置作为内存最大值后对于数据的剔除策略。
- 一致性：要清理哪些数据是由具体算法决定，开发人员只能决定使用哪种算法，所以数据的一致性是最差的。
- 维护成本：算法不需要开发人员自己来实现，通常只需要配置最大maxmemory和对应的策略即可。开发人员只需要知道每种算法的含义，选择适合自己的算法即可。

2）超时剔除
- 使用场景：超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，例如Redis提供的expire命令。如果业务可以容忍一段时间内，缓存层数据和存储层数据不一致，那么可以为其设置过期时间。在数据过期后，再从真实数据源获取数据，重新放到缓存并设置过期时间。
- 一致性：一段时间窗口内（取决于过期时间长短）存在一致性问题，即缓存数据和真实数据源的数据不一致。
- 维护成本：维护成本不是很高，只需设置expire过期时间即可，当然前提是应用方允许这段时间可能发生的数据不一致。

3）主动更新
- 使用场景：应用方对于数据的一致性要求高，需要在真实数据更新后，立即更新缓存数据。
- 一致性：一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好。
- 维护成本：维护成本会比较高，开发者需要自己来完成更新，并保证更新操作的正确性。

下表为缓存的三种常见更新策略的对比：
策略 | 一致性 | 维护成本
---|---|---
LRU/LFU/FIFO算法剔除 | 最差 | 低
超时剔除 | 较差 | 较低
主动更新 | 强 | 高

4）最佳实践建议
- 低一致性业务建议配置最大内存和淘汰策略的方式使用。
- 高一致性业务可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。

3、 缓存粒度控制

从通用性、空间占用、代码维护三个角度进行说明：
- 通用性。缓存全部数据比部分数据更加通用，但从实际经验看，很长时间内应用只需要几个重要的属性。
- 空间占用。缓存全部数据要比部分数据占用更多的空间，可能存在以问题：
    1. 全部数据会造成内存的浪费。
    2. 全部数据可能每次传输产生的网络流量会比较大，耗时相对较大，在极端情况下会阻塞网络。
    3. 全部数据的序列化和反序列化的CPU开销更大。
- 代码维护。全部数据的优势更加明显，而部分数据一旦要加新字段需要修改业务代码，而且修改后通常还需要刷新缓存数据。

4、穿透优化
- 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层，整个过程分为如下3步：
    1. 缓存层不命中。
    2. 存储层不命中，不将空结果写回缓存。
    3. 返回空结果。
- 缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。
- 缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。通常可以在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。
- 造成缓存穿透的基本原因有两个。第一，自身业务代码或者数据出现问题，第二，一些恶意攻击、爬虫等造成大量空命中。
- 如何解决缓存穿透问题：
    1. 缓存空对象：
        1. 存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，这样就保护了后端数据源。
        2. 缓存空对象会有两个问题：第一，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。第二，缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。
    2. 布隆过滤器拦截
        1. 在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截。例如： 一个推荐系统有4亿个用户id，每个小时算法工程师会根据每个用户之前历史行为计算出推荐数据放到存储层中，但是最新的用户由于没有历史行为，就会发生缓存穿透的行为，为此可以将所有推荐数据的用户做成布隆过滤器。如果布隆过滤器认为该用户id不存在，那么就不会访问存储层，在一定程度保护了存储层。
        2. 可以利用Redis的Bitmaps实现布隆过滤器。
        3. 这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。

下表为缓存空对象和布隆过滤器方案对比：
解决缓存穿透 | 使用场景 | 维护成本
---|---|---
缓存空对象 | - 数据命中不高<br>- 数据频繁变化实时性高 | - 代码维护简单<br>- 需要过多的缓存空间<br>- 数据不一致
布隆过滤器 | - 数据命中不高<br>- 数据相对固定实时性低 | - 代码维护复杂<br>- 缓存空间占用少

5、无底洞优化

- 通常来说添加节点使得Memcache集群性能应该更强了，但事实并非如此。键值数据库由于通常采用哈希函数将key映射到各个节点上，造成key的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的节点上，所以无论是Memcache还是Redis的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。
- 无底洞问题分析：
    1. 客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。
    2. 网络连接数变多，对节点的性能也有一定影响。
- 更多的节点不代表更高的性能，所谓“无底洞”就是说投入越多不一定产出越多。但是分布式又是不可以避免的，因为访问量和数据量越来越大，一个节点根本抗不住。
- 常见的IO优化思路：
    1. 命令本身的优化，例如优化SQL语句等。
    2. 减少网络通信次数。
    3. 降低接入成本，例如客户端使用长连/连接池、NIO等。
- 结合Redis Cluster的一些特性对四种分布式的批量操作方式进行说明：、
    1. 串行命令：由于n个key是比较均匀地分布在Redis Cluster的各个节点上，因此无法使用mget命令一次性获取，所以通常来讲要获取n个key的值，最简单的方法就是逐次n个get命令，这种操作时间复杂度较高，它的操作时间=n次网络时间+n次命令时间，网络次数是n。很显然这种方案不是最优的，但是实现起来比较简单。
    2. 串行IO：Redis Cluster使用CRC16算法计算出散列值，再取对16383的余数就可以算出slot值，同时Smart客户端会保存slot和节点的对应关系，有了这两个数据就可以将属于同一个节点的key进行归档，得到每个节点的key子列表，之后对每个节点执行mget或者Pipeline操作，它的操作时间=node次网络时间+n次命令时间，网络次数是node的个数。很明显这种方案比第一种要好很多，但是如果节点数太多，还是有一定的性能问题。
    3. 并行IO：此方案是将方案2中的最后一步改为多线程执行，网络次数虽然还是节点个数，但由于使用多线程网络时间变为O（1），这种方案会增加编程的复杂度。
    4. hash_tag实现：它可以将多个key强制分配到一个节点上，它的操作时间=1次网络时间+n次命令时间。

下表为四种批量操作解决方案对比：
方案 | 优点 | 缺点 | 网络IO
---|---|---|---
串行命令 | 1）编程简单<br>2）如果少量keys，性能可以满足要求 | 大量keys请求延迟严重 | O(keys)
串行IO | 1）编程简单<br>2）少量节点，性能满足要求 | 大量node延迟严重 | O(nodes)
并行IO | 利用并行特性，延迟取决于最慢的节点 | 1）编程复杂<br>2）由于多线程，问题定位可能较难 | O(max_slow(nodes))
hash_tag | 性能最高 | 1）业务维护成本较高<br>2）容易出现数据倾斜 | O(1)

6、雪崩优化

- 缓存雪崩：由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联宕机的情况。缓存雪崩的英文原意是stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。
- 预防和解决缓存雪崩问题，可以从以下三个方面进行着手：
    1. 保证缓存层服务高可用性
    2. 依赖隔离组件为后端限流并降级：作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部阻塞（hang）在这个资源上，造成整个系统不可用。在实际项目中，我们需要对重要的资源（例如Redis、MySQL、HBase、外部接口）都进行隔离，让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响。
    3. 提前演练。

7、热点key重建优化
- 开发人员使用“缓存+过期时间”的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害：
    1. 当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。
    2. 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。
    3. 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。

1）互斥锁
- 此方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。(可以通过setnx命令实现)

2）永远不过期
- “永远不过期”包含两层意思：
    1. 从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。
    2. 从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。
- 从实战看，此方法有效杜绝了热点key产生的问题，但唯一不足的就是重构缓存期间，会出现数据不一致的情况，这取决于应用方是否容忍这种不一致。

- 互斥锁（mutex key）：这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。
- “永远不过期” ：这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。

下表为两种热点key的解决方法：

解决方案 | 优点 | 缺点
---|---|---
简单分布式锁 | - 思路简单<br>- 保证一致性 | - 代码复杂度增大<br>- 存在死锁的风险<br>- 存在线程池阻塞的风险
“永远不过期” | 基本杜绝热点key问题 | - 不保证一致性<br>- 逻辑过期时间增加代码维护成本和内存成本

8、汇总
- 比较推荐的缓存更新策略是结合剔除、超时、主动更新三种方案共同完成。
- 穿透问题：使用缓存空对象和布隆过滤器来解决，注意它们各自的使用场景和局限性。
- 无底洞问题：分布式缓存中，有更多的机器不保证有更高的性能。有四种批量操作方式：串行命令、串行IO、并行IO、hash_tag。
- 雪崩问题：缓存层高可用、客户端降级、提前演练是解决雪崩问题的重要方法。
- 热点key问题：互斥锁、“永远不过期”能够在一定程度上解决热点key问题，开发人员在使用时要了解它们各自的使用成本。
